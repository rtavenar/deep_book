{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca41b925",
   "metadata": {},
   "source": [
    "(sec:sgd)=\n",
    "# Optimization\n",
    "\n",
    "In this chapter, we will present variants of the **Gradient Descent** optimization strategy and show how they can be used to optimize neural network parameters.\n",
    "\n",
    "Let us start with the basic Gradient Descent algorithm and its limitations.\n",
    "\n",
    "```{prf:algorithm} Gradient Descent\n",
    ":label: algo:gd\n",
    "\n",
    "**Input:** A dataset $\\mathcal{D} = (X, y)$\n",
    "\n",
    "1. Initialize model parameters $\\theta$\n",
    "2. for $e = 1 .. E$\n",
    "\n",
    "    1. for $(x_i, y_i) \\in \\mathcal{D}$\n",
    "\n",
    "        1. Compute prediction $\\hat{y}_i = m_\\theta(x_i)$\n",
    "        2. Compute gradient $\\nabla_\\theta \\mathcal{L}_i$\n",
    "\n",
    "    2. Compute overall gradient $\\nabla_\\theta \\mathcal{L} = \\frac{1}{n} \\sum_i \\nabla_\\theta \\mathcal{L}_i$\n",
    "    3. Update parameters $\\theta$ based on $\\nabla_\\theta \\mathcal{L}$\n",
    "```\n",
    "\n",
    "The typical update rule for the parameters $\\theta$ is\n",
    "\n",
    "$$\n",
    "    \\theta \\leftarrow \\theta - \\rho \\nabla_\\theta \\mathcal{L}\n",
    "$$\n",
    "\n",
    "where $\\rho$ is an important hyper-parameter of the method, called the learning rate.\n",
    "Basically, gradient descent updates $\\theta$ in the direction of steepest decrease of the loss $\\mathcal{L}$.\n",
    "\n",
    "As one can see in the previous algorithm, when performing gradient descent, model parameters are updated once per epoch, which means a full pass over the whole dataset is required before the update can occur.\n",
    "When dealing with large datasets, this is a strong limitation, which motivates the use of stochastic variants.\n",
    "\n",
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The idea behind the Stochastic Gradient Descent algorithm is to get cheap estimates for the quantity \n",
    "\n",
    "$$\n",
    "    \\nabla_\\theta \\mathcal{L}(\\mathcal{D} ; m_\\theta) = \\frac{1}{n} \\sum_{(x_i, y_i) \\in \\mathcal{D}} \\nabla_\\theta \\mathcal{L}(x_i, y_i ; m_\\theta)\n",
    "$$\n",
    "\n",
    "where $\\mathcal{D}$ is the whole training set.\n",
    "To do so, one draws subsets of data, called _minibatches_, and \n",
    "\n",
    "$$\n",
    "    \\nabla_\\theta \\mathcal{L}(\\mathcal{B} ; m_\\theta) = \\frac{1}{b} \\sum_{(x_i, y_i) \\in \\mathcal{B}} \\nabla_\\theta \\mathcal{L}(x_i, y_i ; m_\\theta)\n",
    "$$\n",
    "is used as an estimator for $\\nabla_\\theta \\mathcal{L}(\\mathcal{D} ; m_\\theta)$.\n",
    "This results in the following algorithm in which, interestingly, parameter updates occur after each minibatch, which is multiple times per epoch.\n",
    "\n",
    "```{prf:algorithm} Stochastic Gradient Descent\n",
    ":label: algo:sgd\n",
    "\n",
    "**Input:** A dataset $\\mathcal{D} = (X, y)$\n",
    "\n",
    "1. Initialize model parameters $\\theta$\n",
    "2. for $e = 1 .. E$\n",
    "\n",
    "    1. for $t = 1 .. n_\\text{minibatches}$\n",
    "\n",
    "        1. Draw minibatch $\\mathcal{B}$ as a random sample of size $b$ from $\\mathcal{D}$\n",
    "        1. for $(x_i, y_i) \\in \\mathcal{B}$\n",
    "\n",
    "            1. Compute prediction $\\hat{y}_i = m_\\theta(x_i)$\n",
    "            2. Compute gradient $\\nabla_\\theta \\mathcal{L}_i$\n",
    "\n",
    "        2. Compute minibatch-level gradient $\\nabla_\\theta \\mathcal{L}_\\mathcal{B} = \\frac{1}{b} \\sum_i \\nabla_\\theta \\mathcal{L}_i$\n",
    "        3. Update parameters $\\theta$ based on $\\nabla_\\theta \\mathcal{L}_\\mathcal{B}$\n",
    "```\n",
    "\n",
    "As a consequence, when using SGD, parameter updates are more frequent, but they are \"noisy\" since they are based on an minibatch estimation of the gradient instead of relying on the true gradient, as illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6dd919",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manimation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01manimation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rc\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(X, y, alpha, lambd):\n\u001b[1;32m     16\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39my \u001b[38;5;241m*\u001b[39m X\u001b[38;5;241m.\u001b[39mdot(alpha))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.ion();\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "import scipy.optimize as optim\n",
    "\n",
    "\n",
    "def grad(X, y, alpha, lambd):\n",
    "    p = np.exp(-y * X.dot(alpha))\n",
    "    d = - X.T.dot(p * y / (1 + p)) + lambd * alpha\n",
    "    return d\n",
    "\n",
    "def norm(x):\n",
    "    return np.sqrt(np.sum(x ** 2))\n",
    "\n",
    "def cost(X, y, alpha, lambd):\n",
    "    p = np.exp(-y * X.dot(alpha))\n",
    "    return np.sum(np.log(1 + p)) + .5 * lambd * norm(alpha) ** 2\n",
    "    # TODO: 1/n pour pas que le SGD fasse nimp\n",
    "\n",
    "\n",
    "def optim_gd(X, y, alpha_init, n_epochs, lambd, rho):\n",
    "    alphas = [alpha_init]\n",
    "    for _ in range(n_epochs):\n",
    "        d = - grad(X, y, alphas[-1], lambd)        \n",
    "        alphas.append(alphas[-1] + rho * d)\n",
    "\n",
    "    return np.concatenate(alphas, axis=0).reshape((-1, alpha_init.shape[0]))\n",
    "\n",
    "\n",
    "def optim_sgd(X, y, alpha_init, n_epochs, lambd, rho, minibatch_size):\n",
    "    alphas = [alpha_init]\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(X.shape[0] // minibatch_size):\n",
    "            scaled_lambda = lambd / (X.shape[0] // minibatch_size)\n",
    "            indices_minibatch = np.random.randint(X.shape[0], size=minibatch_size)\n",
    "            X_minibatch = X[indices_minibatch]\n",
    "            y_minibatch = y[indices_minibatch]\n",
    "            d = - grad(X_minibatch, y_minibatch, alphas[-1], scaled_lambda)\n",
    "              \n",
    "            alphas.append(alphas[-1] + rho * d)\n",
    "\n",
    "    return np.concatenate(alphas, axis=0).reshape((-1, alpha_init.shape[0]))\n",
    "\n",
    "\n",
    "def stretch_to_range(lim, sz_range):\n",
    "    middle = (lim[0] + lim[1]) / 2\n",
    "    return [middle - sz_range / 2, middle + sz_range / 2]\n",
    "\n",
    "\n",
    "def get_lims(*alphas_list):\n",
    "    xlims = [\n",
    "        min([alphas[:, 0].min() for alphas in alphas_list]) - 1,\n",
    "        max([alphas[:, 0].max() for alphas in alphas_list]) + 1\n",
    "    ]\n",
    "    ylims = [\n",
    "        min([alphas[:, 1].min() for alphas in alphas_list]) - 1,\n",
    "        max([alphas[:, 1].max() for alphas in alphas_list]) + 1\n",
    "    ]\n",
    "    if xlims[1] - xlims[0] > ylims[1] - ylims[0]:\n",
    "        ylims = stretch_to_range(ylims, xlims[1] - xlims[0])\n",
    "    else:\n",
    "        xlims = stretch_to_range(xlims, ylims[1] - ylims[0])\n",
    "    return xlims, ylims\n",
    "\n",
    "\n",
    "def gen_anim(X, y, alphas_gd, alphas_sgd, alpha_star, lambd, xlims, ylims, n_steps_per_epoch):\n",
    "    global lines_alphas\n",
    "    font = {'size'   : 18}\n",
    "    rc('font', **font)\n",
    "\n",
    "    n = 40\n",
    "    nn = n * n\n",
    "    xv, yv = np.meshgrid(np.linspace(xlims[0], xlims[1], n),\n",
    "                         np.linspace(ylims[0], ylims[1], n))\n",
    "    xvisu = np.concatenate((xv.ravel()[:, None], yv.ravel()[:, None]), axis=1)\n",
    "\n",
    "    pv = np.zeros(nn)\n",
    "    for i in range(nn):\n",
    "        pv[i] = cost(X, y, xvisu[i], lambd)\n",
    "\n",
    "    P = pv.reshape((n,n))\n",
    "    \n",
    "    fig = plt.figure(figsize=(13, 6))\n",
    "    axes = [plt.subplot(1, 2, i + 1) for i in range(2)]\n",
    "\n",
    "    lines_alphas = []\n",
    "    texts = []  \n",
    "    for ax, alphas, title in zip(axes, \n",
    "                                 [alphas_gd, alphas_sgd],\n",
    "                                 [\"Gradient Descent\", \"Stochastic Gradient Descent\"]):\n",
    "        ax.contour(xv, yv, P, alpha=0.5)\n",
    "        ax.plot(alphas[0, 0], alphas[0, 1], 'ko', fillstyle='none')\n",
    "        line_alphas,  = ax.plot(alphas[:1, 0], alphas[:1, 1], marker=\"x\")\n",
    "        lines_alphas.append(line_alphas)\n",
    "        \n",
    "        ax.plot(alpha_star[0:1], alpha_star[1:2], '+r')\n",
    "\n",
    "        ax.set_xlabel(\"$w_0$\")\n",
    "        ax.set_ylabel(\"$w_1$\")\n",
    "        ax.set_xlim(xlims)\n",
    "        ax.set_ylim(ylims)\n",
    "        ax.set_title(title)\n",
    "        text_epoch = ax.text(0.7 * xlims[1], 0.8 * ylims[1], s=\"Epoch 0\")\n",
    "        texts.append(text_epoch)\n",
    "\n",
    "    def animate(i):\n",
    "        global lines_alphas\n",
    "        \n",
    "        for line_alphas, text_epoch, alphas in zip(lines_alphas, texts, [alphas_gd, alphas_sgd]):\n",
    "            line_alphas.set_xdata(alphas[:i, 0])\n",
    "            line_alphas.set_ydata(alphas[:i, 1])\n",
    "            \n",
    "            text_epoch.set_text(f\"Epoch {i // n_steps_per_epoch}\")\n",
    "        return lines_alphas + texts\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate, interval=500, blit=False, save_count=len(alphas_gd))\n",
    "\n",
    "\n",
    "# Data\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(20, 2) * 3 - 1.5\n",
    "y = (X[:, 0] > 0.).astype(np.int)\n",
    "y[y == 0] = -1\n",
    "\n",
    "# Optim\n",
    "\n",
    "lambd = .1\n",
    "rho = 2e-1\n",
    "alpha_init = np.array([1., -3.])\n",
    "n_epochs = 10\n",
    "minibatch_size = 4\n",
    "\n",
    "res_optim = optim.minimize(fun=lambda alpha: cost(X, y, alpha, lambd),\n",
    "                           x0=alpha_init, \n",
    "                           jac=lambda alpha: grad(X, y, alpha, lambd))\n",
    "alpha_star = res_optim[\"x\"]\n",
    "\n",
    "alphas_gd = optim_gd(X, y, alpha_init, n_epochs, lambd, rho)\n",
    "alphas_sgd = optim_sgd(X, y, alpha_init, n_epochs, lambd, rho, minibatch_size)\n",
    "\n",
    "# Visualization\n",
    "xlims, ylims = get_lims(alphas_gd, alphas_sgd, np.array([alpha_star]))\n",
    "\n",
    "ani = gen_anim(X, y, \n",
    "               np.repeat(alphas_gd, 20 // minibatch_size, axis=0), alphas_sgd,\n",
    "               alpha_star, lambd, xlims, ylims, \n",
    "               n_steps_per_epoch=20 // minibatch_size)\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5ac59",
   "metadata": {},
   "source": [
    "Apart from implying from more frequent parameter updates, SGD has an extra benefit in terms of optimization, which is key for neural networks.\n",
    "Indeed, as one can see below, contrary to what we had in the Perceptron case, the MSE loss (and the same applies for the logistic loss) is no longer convex in the model parameters as soon as the model has at least one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a3f72",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def model_forward_loss(weights, biases, X, y):\n",
    "    outputs = X\n",
    "    for w, b in zip(weights, biases):\n",
    "        outputs = sigmoid(outputs @ w + b)\n",
    "    loss = np.mean((outputs - y) ** 2)\n",
    "    loss += .0001 * np.sum([(w ** 2).sum() for w in weights])\n",
    "    return loss\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "w0 = np.linspace(-5, 5, 100)\n",
    "X = np.random.randn(150, 6)\n",
    "y = np.array([0] * 75 + [1] * 75)\n",
    "weights = [\n",
    "    np.random.randn(6, 20),\n",
    "    np.random.randn(20, 1)\n",
    "]\n",
    "biases = [\n",
    "    np.random.randn(1, 20),\n",
    "    np.random.randn(1, 1)\n",
    "]\n",
    "\n",
    "losses = []\n",
    "for wi in w0:\n",
    "    weights[0][3, 9] = wi\n",
    "    losses.append(model_forward_loss(weights, biases, X, y))\n",
    "\n",
    "\n",
    "plt.plot(w0, losses)\n",
    "plt.grid('on')\n",
    "plt.xlabel('$w$')\n",
    "plt.ylabel('$\\mathcal{L}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62486e",
   "metadata": {},
   "source": [
    "Gradient Descent is known to suffer from local optima, and such loss landscapes are a serious problem for GD.\n",
    "On the other hand, Stochastic Gradient Descent is likely to benefit from noisy gradient estimations to escape local minima.\n",
    "\n",
    "## A note on Adam\n",
    "\n",
    "**TODO: explain formulas**\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{m}^{(t+1)} & \\propto &  \\beta_1 \\mathbf{m}^{(t)} + (1 - \\beta_1) \\nabla_\\theta \\mathcal{L} \\\\\n",
    "    \\mathbf{s}^{(t+1)} & \\propto &  \\beta_{2} \\mathbf{s}^{(t)} + (1-\\beta_{2}) \\nabla_{\\theta} \\mathcal{L} \\otimes \\nabla_{\\theta} \\mathcal{L} \\\\\n",
    "    \\theta^{(t+1)} & \\leftarrow & \\theta^{(t)} - \\rho \\mathbf{m}^{(t+1)} \\oslash \\sqrt{\\mathbf{s}^{(t+1)}+\\epsilon}\n",
    "\\end{align*}\n",
    "\n",
    "**TODO: illustrate SGD, SGD+momentum, Adam on a given optimization problem**\n",
    "\n",
    "## The curse of depth\n",
    "\n",
    "**TODO:** MLP illustration with colors and chain rule\n",
    "\n",
    "**TODO:** A first implication: use ReLU activation functions if you have no reason to use anything else. (illustrate this?)\n",
    "\n",
    "**TODO**: talk about feature standardization and how it eases the convergence to a good solution\n",
    "\n",
    "## Wrapping things up in `keras`\n",
    "\n",
    "In `keras`, loss and optimizer information are passed at compile time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4366e",
   "metadata": {
    "tags": [
     "remove-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(10, )),\n",
    "    Dense(units=20, activation=\"relu\"),\n",
    "    Dense(units=3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896e9f6",
   "metadata": {
    "tags": [
     "remove-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbb03f",
   "metadata": {},
   "source": [
    "In terms of losses:\n",
    "\n",
    "* `\"mse\"` is the mean squared error loss,\n",
    "* `\"binary_crossentropy\"` is the logistic loss for binary classification,\n",
    "* `\"categorical_crossentropy\"` is the logistic loss for multi-class classification.\n",
    "\n",
    "The optimizers defined in this section are available as `\"sgd\"` and `\"adam\"`.\n",
    "In order to get control over optimizer hyper-parameters, one can alternatively use the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a47dc",
   "metadata": {
    "tags": [
     "remove-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# `lr` stands for learning rate \n",
    "# Not a very good idea to tune beat_1 and beta_2 parameters in Adam\n",
    "adam_opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.9)\n",
    "\n",
    "# In order to use SGD with a custom learning rate:\n",
    "# sgd_opt = SGD(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_opt)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.9.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "source_map": [
   14,
   91,
   252,
   258,
   296,
   326,
   342,
   346,
   358
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}