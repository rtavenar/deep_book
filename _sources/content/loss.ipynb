{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf17e6c",
   "metadata": {},
   "source": [
    "(sec:loss)=\n",
    "# Losses\n",
    "\n",
    "We have now presented a first family of models, which is the MLP family.\n",
    "In order to train these models (_i.e._ tune their parameters to fit the data), we need to define a loss function to be optimized.\n",
    "Indeed, once this loss function is picked, optimization will consist in tuning the model parameters so as to minimize the loss.\n",
    "\n",
    "In this section, we will present two standard losses, that are the mean squared error (that is mainly used for regression) and logistic loss (that is mostly used in classification settings).\n",
    "\n",
    "## Mean Squared Error (MSE)\n",
    "\n",
    "## Logistic loss\n",
    "\n",
    "**TODO: ici, parler de non convexité, idéalement illustrer (peut-être sur Iris ?)**\n",
    "\n",
    "## Loss regularizers"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.9.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "source_map": [
   14
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}