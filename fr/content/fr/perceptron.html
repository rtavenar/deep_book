
<!DOCTYPE html>

<html lang="fr">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Introduction &#8212; Introduction au Deep Learning (notes de cours)</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Recherche" href="../../search.html" />
    <link rel="next" title="Perceptrons multicouches" href="mlp.html" />
    <link rel="prev" title="Introduction au Deep Learning" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="fr">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction au Deep Learning (notes de cours)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction au Deep Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mlp.html">
   Perceptrons multicouches
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="loss.html">
   Fonctions de coût
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optim.html">
   Optimisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="regularization.html">
   Régularisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convnets.html">
   Réseaux neuronaux convolutifs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rnn.html">
   Réseaux neuronaux récurrents
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            <div><a href="../../../book_fr.pdf">Télécharger ces notes en PDF</a><br />
<a href="../../../en/index.html">Switch to English</a></div>

            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/rtavenar/deep_book/main?urlpath=tree/content/fr/perceptron.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/rtavenar/deep_book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/rtavenar/deep_book/issues/new?title=Issue%20on%20page%20%2Fcontent/fr/perceptron.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/content/fr/perceptron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../../_sources/content/fr/perceptron.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#un-premier-modele-le-perceptron">
   Un premier modèle : le perceptron
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimisation">
   Optimisation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#descente-de-gradient">
     Descente de gradient
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recapitulatif">
   Récapitulatif
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#un-premier-modele-le-perceptron">
   Un premier modèle : le perceptron
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimisation">
   Optimisation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#descente-de-gradient">
     Descente de gradient
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#recapitulatif">
   Récapitulatif
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Lien permanent vers ce titre">#</a></h1>
<p>Dans ce chapitre d’introduction, nous allons présenter un premier réseau neuronal appelé
le Perceptron.
Ce modèle est un réseau neuronal constitué d’un seul neurone, et nous l’utiliserons ici pour introduire des concepts-clés que nous détaillerons plus tard dans le cours.</p>
<div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;svg&#39;
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">notebook_utils</span> <span class="kn">import</span> <span class="n">prepare_notebook_graphics</span>
<span class="n">prepare_notebook_graphics</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="un-premier-modele-le-perceptron">
<h2>Un premier modèle : le perceptron<a class="headerlink" href="#un-premier-modele-le-perceptron" title="Lien permanent vers ce titre">#</a></h2>
<p>Dans la terminologie des réseaux de neurones, un neurone est une fonction paramétrée qui
prend un vecteur <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> en entrée et sort une valeur unique <span class="math notranslate nohighlight">\(a\)</span> comme suit :</p>
<div class="math notranslate nohighlight">
\[
    a = \varphi(\underbrace{\mathbf{w} \mathbf{x} + b}_{o}) ,
\]</div>
<p>où les paramètres du neurone sont ses poids stockés dans <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>.
et un terme de biais <span class="math notranslate nohighlight">\(b\)</span>, et <span class="math notranslate nohighlight">\(\varphi\)</span> est une fonction d’activation qui est choisie
a priori
(nous y reviendrons plus en détail plus tard dans le cours) :</p>
<div class="figure" style="text-align: center"><p><img  src="../../_images/tikz-dbe7456fde9972163cde15b20b8daf6303bfbb7d.svg" alt="Figure made with TikZ" /></p>
</div><p>Un modèle constitué d’un seul neurone est appelé perceptron.</p>
</section>
<section id="optimisation">
<h2>Optimisation<a class="headerlink" href="#optimisation" title="Lien permanent vers ce titre">#</a></h2>
<p>Les modèles présentés dans ce document ont pour but de résoudre des problèmes de prédiction
dans lesquels l’objectif est de trouver des valeurs de paramètres « suffisamment bonnes » pour le modèle en jeu
compte tenu de données observées.</p>
<p>Le problème de la recherche de telles valeurs de paramètres est appelé optimisation.
L’apprentissage profond (ou <em>deep learning</em>) fait un usage intensif d’une famille spécifique de stratégies d’optimisation appelée <strong>descente gradiente</strong>.</p>
<section id="descente-de-gradient">
<span id="sec-boston"></span><h3>Descente de gradient<a class="headerlink" href="#descente-de-gradient" title="Lien permanent vers ce titre">#</a></h3>
<p>Pour se faire une idée de la descente de gradient, supposons que l’on nous donne le jeu de données suivant sur les prix de l’immobilier :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">boston</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/boston.csv&quot;</span><span class="p">)[[</span><span class="s2">&quot;RM&quot;</span><span class="p">,</span> <span class="s2">&quot;PRICE&quot;</span><span class="p">]]</span>
<span class="n">boston</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RM</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.575</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.421</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.185</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.998</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.147</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>6.593</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>6.120</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>6.976</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>6.794</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>6.030</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 2 columns</p>
</div></div></div>
</div>
<p>Dans notre cas, nous essaierons (pour commencer) de prédire la valeur cible <code class="docutils literal notranslate"><span class="pre">&quot;PRICE&quot;</span></code> de ce jeu de données, qui est la valeur médiane des maisons occupées par leur propriétaire en milliers de dollars en fonction du nombre moyen de pièces par logement <code class="docutils literal notranslate"><span class="pre">&quot;RM&quot;</span></code> :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">boston</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;RM&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;PRICE&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/perceptron_5_0.svg" src="../../_images/perceptron_5_0.svg" /></div>
</div>
<aside class="sidebar">
<p class="sidebar-title">Une courte note sur ce modèle</p>
<p>Dans la terminologie du Perceptron, ce modèle :</p>
<ul class="simple">
<li><p>n’a pas de fonction d’activation (<em>i.e.</em> <span class="math notranslate nohighlight">\(\varphi\)</span> est la fonction d’identité)</p></li>
<li><p>n’a pas de biais (<em>i.e.</em> <span class="math notranslate nohighlight">\(b\)</span> est fixé à <span class="math notranslate nohighlight">\(0\)</span>, il n’est pas appris)</p></li>
</ul>
</aside>
<p>Supposons que nous ayons une approche naïve dans laquelle notre modèle de prédiction est linéaire sans biais, c’est-à-dire que pour une entrée donnée <span class="math notranslate nohighlight">\(x_i\)</span> la sortie prédite est
calculée comme suit :</p>
<div class="math notranslate nohighlight">
\[
    \hat{y_i} = w x_i
\]</div>
<p>où <span class="math notranslate nohighlight">\(w\)</span> est le seul paramètre de notre modèle.</p>
<p>Supposons en outre que la quantité que nous cherchons à minimiser
(notre objectif, également appelé fonction de perte) est :</p>
<div class="math notranslate nohighlight">
\[
    \mathcal{L}(w) = \sum_i \left(\hat{y_i} - y_i\right)^2
\]</div>
<p>où <span class="math notranslate nohighlight">\(y_i\)</span> est la valeur cible associée au <span class="math notranslate nohighlight">\(i\)</span>-ème échantillon de jeu de données.</p>
<p>Examinons cette quantité en fonction de <span class="math notranslate nohighlight">\(w\)</span> :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="p">(</span><span class="n">w</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s2">&quot;RM&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s2">&quot;PRICE&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;r-&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/perceptron_7_0.svg" src="../../_images/perceptron_7_0.svg" /></div>
</div>
<p>Ici, il semble qu’une valeur de <span class="math notranslate nohighlight">\(w\)</span> autour de 4 devrait être un bon choix.
Cette méthode (générer de nombreuses valeurs pour le paramètre et calculer la perte pour
chaque valeur) ne peut pas s’adapter aux modèles qui ont beaucoup de paramètres, donc nous allons
donc essayer autre chose.</p>
<p>Supposons que nous ayons accès, à chaque fois que nous choisissons une valeur candidate pour <span class="math notranslate nohighlight">\(w\)</span>,
à la fois à la perte <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> et aux informations sur la façon dont <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> varie,
localement.
Nous pourrions, dans ce cas, calculer une nouvelle valeur candidate pour <span class="math notranslate nohighlight">\(w\)</span> en nous déplaçant à partir de la valeur candidate précédente dans la direction de la descente la plus raide.
C’est l’idée de base de l’algorithme de descente du gradient qui, à partir d’un candidat initial <span class="math notranslate nohighlight">\(w_0\)</span>, calcule itérativement de nouveaux candidats comme :</p>
<div class="math notranslate nohighlight">
\[
    w_{t+1} = w_t - \rho \left. \frac{\partial \mathcal{L}}{\partial w} \right|_{w=w_t}
\]</div>
<p>où <span class="math notranslate nohighlight">\(\rho\)</span> est un hyper-paramètre (appelé taux d’apprentissage)
qui contrôle la taille des pas à effectuer, et
<span class="math notranslate nohighlight">\(\left. \frac{\partial \mathcal{L}}{\partial w} \right|_{w=w_t}\)</span> est le
gradient de
<span class="math notranslate nohighlight">\(\mathcal{L}\)</span> par rapport à <span class="math notranslate nohighlight">\(w\)</span>, évalué en <span class="math notranslate nohighlight">\(w=w_t\)</span>.
Comme vous pouvez le voir, la direction de la descente la plus raide est l’opposé de la direction indiquée par le gradient (et cela vaut aussi pour les paramètres vectoriels).</p>
<p>Ce processus est répété jusqu’à la convergence, comme l’illustre la figure suivante :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="k">def</span> <span class="nf">grad_loss</span><span class="p">(</span><span class="n">w_t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">w_t</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>
    <span class="p">)</span>


<span class="n">ww</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;r-&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">);</span>

<span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">w_update</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">grad_loss</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_update</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;ko-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mf">.1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{0}</span><span class="s2">$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">+</span><span class="mf">.1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{10}</span><span class="s2">$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/perceptron_9_0.svg" src="../../_images/perceptron_9_0.svg" /></div>
</div>
<p>Qu’obtiendrions-nous si nous utilisions un taux d’apprentissage plus faible ?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="mf">1e-6</span>

<span class="n">ww</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;r-&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">);</span>

<span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">w_update</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">grad_loss</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_update</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;ko-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mf">.1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{0}</span><span class="s2">$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">+</span><span class="mf">.1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{10}</span><span class="s2">$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/perceptron_11_0.svg" src="../../_images/perceptron_11_0.svg" /></div>
</div>
<p>Cela prendrait certainement plus de temps pour converger.
Mais attention, un taux d’apprentissage plus élevé n’est pas toujours une bonne idée :</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rho</span> <span class="o">=</span> <span class="mf">5e-5</span>

<span class="n">ww</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">ww</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;r-&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">);</span>

<span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">w_update</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">grad_loss</span><span class="p">(</span><span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">w</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w_update</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">loss</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="s2">&quot;ko-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{0}</span><span class="s2">$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">loss</span><span class="p">([</span><span class="n">w</span><span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="s2">&quot;$w_</span><span class="si">{10}</span><span class="s2">$&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/perceptron_13_0.svg" src="../../_images/perceptron_13_0.svg" /></div>
</div>
<p>Vous voyez comment nous divergeons lentement parce que nos pas sont trop grands ?</p>
</section>
</section>
<section id="recapitulatif">
<h2>Récapitulatif<a class="headerlink" href="#recapitulatif" title="Lien permanent vers ce titre">#</a></h2>
<p>Dans cette section, nous avons introduit :</p>
<ul class="simple">
<li><p>un modèle très simple, appelé le Perceptron : ce sera une brique de base pour les modèles plus avancés que nous détaillerons plus tard dans le cours, tels que :</p>
<ul>
<li><p>le <a class="reference internal" href="mlp.html#sec-mlp"><span class="std std-ref">Perceptron multi-couches</span></a></p></li>
<li><p>les <a class="reference internal" href="convnets.html#sec-cnn"><span class="std std-ref">architectures convolutionnelles</span></a></p></li>
<li><p>les <a class="reference internal" href="rnn.html#sec-rnn"><span class="std std-ref">architectures récurrentes</span></a></p></li>
</ul>
</li>
<li><p>le fait qu’une tâche s’accompagne d’une fonction de perte à minimiser (ici, nous avons utilisé l’erreur quadratique moyenne pour notre tâche de régression), qui sera discutée dans <a class="reference internal" href="loss.html#sec-loss"><span class="std std-ref">un chapitre dédié</span></a> ;</p></li>
<li><p>le concept de descente de gradient pour optimiser la perte choisie sur le paramètre unique d’un modèle, et ceci sera étendu dans <a class="reference internal" href="optim.html#sec-sgd"><span class="std std-ref">notre chapitre sur l’optimisation</span></a>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/fr"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="intro.html" title="précédent page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">précédent</p>
            <p class="prev-next-title">Introduction au Deep Learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="mlp.html" title="suivant page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">suivant</p>
        <p class="prev-next-title">Perceptrons multicouches</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Romain Tavenard<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>